{
    "page_content": "# LangGraph.js - Quickstart\u00b6\n\n## Introduction\u00b6\n\nIn this quickstart guide, you'll get up and running with a simple Reason + Act Agent (often called a ReAct Agent) that can search the web using Tavily Search API. The code is fully configurable. You can:\n\n  * swap out components\n  * customize the execution flow\n  * extend it with custom code or tooling\n  * change the Large Language Model (LLM) and provider being used\n\n\n\n## Prerequisites\u00b6\n\nTo follow along, you'll need to have the following:\n\n  * NodeJS version 18 or newer\n  * A Tavily account and API key\n  * An OpenAI developer platform account and API key\n\n\n\nStart by creating a new folder for the project. Open your terminal and run the following code:\n[code] \n    mkdir langgraph-agent\n    cd langgraph-agent\n    \n[/code]\n\nYou'll also need to install a few dependencies to create an agent:\n\n  * **langchain/langgraph** contains the building blocks used to assemble an agent\n  * **langchain/openai** enable your agent to use OpenAI's LLMs\n  * **langchain/community** includes the Tavily integration give your agent search capabilities\n\n\n\nYou can install these dependencies using by running following npm command in your terminal:\n[code] \n    npm install @langchain/core @langchain/langgraph @langchain/openai @langchain/community\n    \n[/code]\n\n## LangSmith\u00b6\n\nOptionally, set up LangSmith for best-in-class observability. Setup is simple - add the following variables to your environment and update the `LANGCHAIN_API_KEY` value with your API key.\n[code] \n    // Optional, add tracing in LangSmith\n    // process.env.LANGCHAIN_API_KEY = \"ls__...\";\n    // process.env.LANGCHAIN_CALLBACKS_BACKGROUND = \"true\";\n    // process.env.LANGCHAIN_TRACING_V2 = \"true\";\n    // process.env.LANGCHAIN_PROJECT = \"Quickstart: LangGraphJS\";\n    \n[/code]\n\n## Making your first agent using LangGraph\u00b6\n\nCreate a file named `agent.ts` (short for Reason + Act Agent) and add the below TypeScript code to it.\n\nMake sure you update the environment variables at the top of the file to contain your API keys. If you don't, the OpenAI and Tavily API calls will produce errors and your agent will not work correctly.\n\nOnce you've added your API keys, save the file and run the code with the following command:\n[code] \n    npx tsx agent.ts\n    \n[/code]\n[code] \n    // agent.ts\n    \n    // IMPORTANT - Add your API keys here. Be careful not to publish them.\n    process.env.OPENAI_API_KEY = \"sk-...\";\n    process.env.TAVILY_API_KEY = \"tvly-...\";\n    \n    import { TavilySearchResults } from \"@langchain/community/tools/tavily_search\";\n    import { ChatOpenAI } from \"@langchain/openai\";\n    import { MemorySaver } from \"@langchain/langgraph\";\n    import { HumanMessage } from \"@langchain/core/messages\";\n    import { createReactAgent } from \"@langchain/langgraph/prebuilt\";\n    \n    // Define the tools for the agent to use\n    const agentTools = [new TavilySearchResults({ maxResults: 3 })];\n    const agentModel = new ChatOpenAI({ temperature: 0 });\n    \n    // Initialize memory to persist state between graph runs\n    const agentCheckpointer = new MemorySaver();\n    const agent = createReactAgent({\n      llm: agentModel,\n      tools: agentTools,\n      checkpointSaver: agentCheckpointer,\n    });\n    \n    // Now it's time to use!\n    const agentFinalState = await agent.invoke(\n      { messages: [new HumanMessage(\"what is the current weather in sf\")] },\n      { configurable: { thread_id: \"42\" } },\n    );\n    \n    console.log(\n      agentFinalState.messages[agentFinalState.messages.length - 1].content,\n    );\n    \n    const agentNextState = await agent.invoke(\n      { messages: [new HumanMessage(\"what about ny\")] },\n      { configurable: { thread_id: \"42\" } },\n    );\n    \n    console.log(\n      agentNextState.messages[agentNextState.messages.length - 1].content,\n    );\n    \n[/code]\n[code] \n    The current weather in San Francisco is as follows:\n    - Temperature: 82.0\u00b0F (27.8\u00b0C)\n    - Condition: Sunny\n    - Wind: 11.9 mph from the NW\n    - Humidity: 41%\n    - Pressure: 29.98 in\n    - Visibility: 9.0 miles\n    - UV Index: 6.0\n    \n    For more details, you can visit [Weather in San Francisco](https://www.weatherapi.com/).\n    The current weather in New York is as follows:\n    - Temperature: 84.0\u00b0F (28.9\u00b0C)\n    - Condition: Sunny\n    - Wind: 2.2 mph from SSE\n    - Humidity: 57%\n    - Pressure: 29.89 in\n    - Precipitation: 0.01 in\n    - Visibility: 9.0 miles\n    - UV Index: 6.0\n    \n    For more details, you can visit [Weather in New York](https://www.weatherapi.com/).\n    \n[/code]\n\n## How does it work?\u00b6\n\nThe createReactAgent constructor lets you create a simple tool-using LangGraph agent in a single line of code. Here's a visual representation of the graph:\n[code] \n    // Note: tslab only works inside a jupyter notebook. Don't worry about running this code yourself!\n    import * as tslab from \"tslab\";\n    \n    const graph = agent.getGraph();\n    const image = await graph.drawMermaidPng();\n    const arrayBuffer = await image.arrayBuffer();\n    \n    await tslab.display.png(new Uint8Array(arrayBuffer));\n    \n[/code]\n\n## Customizing agent behavior\u00b6\n\ncreateReactAgent can be great for simple agents, but sometimes you need something more powerful.\n\nLangGraph really shines when you need fine-grained control over an agent's behavior. The following code creates an agent with the same behavior as the example above, but you can clearly see the execution logic and how you could customize it.\n\nUpdate the code in your `agent.ts` file to match the example below. Once again, be sure to update the environment variables at the top.\n\nAfter you've updated your environment variables and saved the file, you can run it with the same command as before:\n[code] \n    npx tsx agent.ts\n    \n[/code]\n[code] \n    // agent.ts\n    \n    // IMPORTANT - Add your API keys here. Be careful not to publish them.\n    process.env.OPENAI_API_KEY = \"sk-...\";\n    process.env.TAVILY_API_KEY = \"tvly-...\";\n    \n    import { TavilySearchResults } from \"@langchain/community/tools/tavily_search\";\n    import { ChatOpenAI } from \"@langchain/openai\";\n    import { HumanMessage, AIMessage } from \"@langchain/core/messages\";\n    import { ToolNode } from \"@langchain/langgraph/prebuilt\";\n    import { StateGraph, MessagesAnnotation } from \"@langchain/langgraph\";\n    \n    // Define the tools for the agent to use\n    const tools = [new TavilySearchResults({ maxResults: 3 })];\n    const toolNode = new ToolNode(tools);\n    \n    // Create a model and give it access to the tools\n    const model = new ChatOpenAI({\n      model: \"gpt-4o-mini\",\n      temperature: 0,\n    }).bindTools(tools);\n    \n    // Define the function that determines whether to continue or not\n    function shouldContinue({ messages }: typeof MessagesAnnotation.State) {\n      const lastMessage = messages[messages.length - 1] as AIMessage;\n    \n      // If the LLM makes a tool call, then we route to the \"tools\" node\n      if (lastMessage.tool_calls?.length) {\n        return \"tools\";\n      }\n      // Otherwise, we stop (reply to the user) using the special \"__end__\" node\n      return \"__end__\";\n    }\n    \n    // Define the function that calls the model\n    async function callModel(state: typeof MessagesAnnotation.State) {\n      const response = await model.invoke(state.messages);\n    \n      // We return a list, because this will get added to the existing list\n      return { messages: [response] };\n    }\n    \n    // Define a new graph\n    const workflow = new StateGraph(MessagesAnnotation)\n      .addNode(\"agent\", callModel)\n      .addEdge(\"__start__\", \"agent\") // __start__ is a special name for the entrypoint\n      .addNode(\"tools\", toolNode)\n      .addEdge(\"tools\", \"agent\")\n      .addConditionalEdges(\"agent\", shouldContinue);\n    \n    // Finally, we compile it into a LangChain Runnable.\n    const app = workflow.compile();\n    \n    // Use the agent\n    const finalState = await app.invoke({\n      messages: [new HumanMessage(\"what is the weather in sf\")],\n    });\n    console.log(finalState.messages[finalState.messages.length - 1].content);\n    \n    const nextState = await app.invoke({\n      // Including the messages from the previous run gives the LLM context.\n      // This way it knows we're asking about the weather in NY\n      messages: [...finalState.messages, new HumanMessage(\"what about ny\")],\n    });\n    console.log(nextState.messages[nextState.messages.length - 1].content);\n    \n[/code]\n\nThere are a few new things going on in this version of our ReAct Agent.\n\nA `ToolNode` enables the LLM to use tools. In this example, we made a `shouldContinue` function and passed it to `addConditionalEdge` so our ReAct Agent can either call a tool or respond to the request.\n\nAnnotations are how graph state is represented in LangGraph. We're using `MessagesAnnotation`, a helper that implements a common pattern: keeping the message history in an array.\n\n## Next Steps\u00b6\n\nGreat job creating your first AI agent using LangGraph! If you're ready to build something more, check out our other tutorials to learn how to implement other end-to-end agentic workflows such as:\n\n  * Retrieval-Augmented Generation (RAG)\n  * Multi-agent collaboration\n  * Reflection, where the agent evaluates its work\n\n\n\nIf you'd rather improve your agent we have how-to guides to help, including:\n\n  * Tool calling that enables agents to interact with APIs\n  * give your agent persistent memory to continue conversations and debug unexpected behavior\n  * Put a human in the loop for actions you want a human to verify\n  * Streaming the agent output to make your application feel more responsive\n  * Change the AI model in one line of code\n\n\n",
    "metadata": {
        "url": "https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/",
        "title": "Learn the basics",
        "description": "Build language agents as graphs",
        "keywords": "No keywords"
    }
}