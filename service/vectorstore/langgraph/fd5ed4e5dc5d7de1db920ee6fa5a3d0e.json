{
    "page_content": "# Storage\u00b6\n\nBase classes and types for persistent key-value stores.\n\nStores provide long-term memory that persists across threads and conversations. Supports hierarchical namespaces, key-value storage, and optional vector search.\n\nCore types\n\n  * BaseStore: Store interface with sync/async operations\n  * Item: Stored key-value pairs with metadata\n  * Op: Get/Put/Search/List operations\n\n\n\n##  `` `NamespacePath = tuple[Union[str, Literal['*']], ...]` `module-attribute` \u00b6\n\nA tuple representing a namespace path that can include wildcards.\n\nExamples\n[code] \n    (\"users\",)  # Exact users namespace\n    (\"documents\", \"*\")  # Any sub-namespace under documents\n    (\"cache\", \"*\", \"v1\")  # Any cache category with v1 version\n    \n[/code]\n\n##  `` `NamespaceMatchType = Literal['prefix', 'suffix']` `module-attribute` \u00b6\n\nSpecifies how to match namespace paths.\n\nValues\n\n\"prefix\": Match from the start of the namespace \"suffix\": Match from the end of the namespace\n\n##  `` `Item` \u00b6\n\nRepresents a stored item with metadata.\n\nParameters:\n\n  * **`value`** (`dict[str, Any]`) \u2013 \n\nThe stored data as a dictionary. Keys are filterable.\n\n  * **`key`** (`str`) \u2013 \n\nUnique identifier within the namespace.\n\n  * **`namespace`** (`tuple[str, ...]`) \u2013 \n\nHierarchical path defining the collection in which this document resides. Represented as a tuple of strings, allowing for nested categorization. For example: (\"documents\", 'user123')\n\n  * **`created_at`** (`datetime`) \u2013 \n\nTimestamp of item creation.\n\n  * **`updated_at`** (`datetime`) \u2013 \n\nTimestamp of last update.\n\n\n\n\n##  `` `SearchItem` \u00b6\n\nBases: `Item`\n\nRepresents an item returned from a search operation with additional metadata.\n\n###  `` `__init__(namespace: tuple[str, ...], key: str, value: dict[str, Any], created_at: datetime, updated_at: datetime, score: Optional[float] = None) -> None` \u00b6\n\nInitialize a result item.\n\nParameters:\n\n  * **`namespace`** (`tuple[str, ...]`) \u2013 \n\nHierarchical path to the item.\n\n  * **`key`** (`str`) \u2013 \n\nUnique identifier within the namespace.\n\n  * **`value`** (`dict[str, Any]`) \u2013 \n\nThe stored value.\n\n  * **`created_at`** (`datetime`) \u2013 \n\nWhen the item was first created.\n\n  * **`updated_at`** (`datetime`) \u2013 \n\nWhen the item was last updated.\n\n  * **`score`** (`Optional[float]`, default: `None` ) \u2013 \n\nRelevance/similarity score if from a ranked operation.\n\n\n\n\n##  `` `GetOp` \u00b6\n\nBases: `NamedTuple`\n\nOperation to retrieve a specific item by its namespace and key.\n\nThis operation allows precise retrieval of stored items using their full path (namespace) and unique identifier (key) combination.\n\nExamples\n\nBasic item retrieval: \n[code]\n    GetOp(namespace=(\"users\", \"profiles\"), key=\"user123\")\n    GetOp(namespace=(\"cache\", \"embeddings\"), key=\"doc456\")\n    \n[/code]\n\n###  `` `namespace: tuple[str, ...]` `instance-attribute` \u00b6\n\nHierarchical path that uniquely identifies the item's location.\n\nExamples\n[code] \n    (\"users\",)  # Root level users namespace\n    (\"users\", \"profiles\")  # Profiles within users namespace\n    \n[/code]\n\n###  `` `key: str` `instance-attribute` \u00b6\n\nUnique identifier for the item within its specific namespace.\n\nExamples\n[code] \n    \"user123\"  # For a user profile\n    \"doc456\"  # For a document\n    \n[/code]\n\n##  `` `SearchOp` \u00b6\n\nBases: `NamedTuple`\n\nOperation to search for items within a specified namespace hierarchy.\n\nThis operation supports both structured filtering and natural language search within a given namespace prefix. It provides pagination through limit and offset parameters.\n\nNote\n\nNatural language search support depends on your store implementation.\n\nExamples\n\nSearch with filters and pagination: \n[code]\n    SearchOp(\n        namespace_prefix=(\"documents\",),\n        filter={\"type\": \"report\", \"status\": \"active\"},\n        limit=5,\n        offset=10\n    )\n    \n[/code]\n\nNatural language search: \n[code]\n    SearchOp(\n        namespace_prefix=(\"users\", \"content\"),\n        query=\"technical documentation about APIs\",\n        limit=20\n    )\n    \n[/code]\n\n###  `` `namespace_prefix: tuple[str, ...]` `instance-attribute` \u00b6\n\nHierarchical path prefix defining the search scope.\n\nExamples\n[code] \n    ()  # Search entire store\n    (\"documents\",)  # Search all documents\n    (\"users\", \"content\")  # Search within user content\n    \n[/code]\n\n###  `` `filter: Optional[dict[str, Any]] = None` `class-attribute` `instance-attribute` \u00b6\n\nKey-value pairs for filtering results based on exact matches or comparison operators.\n\nThe filter supports both exact matches and operator-based comparisons.\n\nSupported Operators\n\n  * $eq: Equal to (same as direct value comparison)\n  * $ne: Not equal to\n  * $gt: Greater than\n  * $gte: Greater than or equal to\n  * $lt: Less than\n  * $lte: Less than or equal to\n\nExamples\n\nSimple exact match:\n[code] \n    {\"status\": \"active\"}\n    \n[/code]\n\nComparison operators:\n[code] \n    {\"score\": {\"$gt\": 4.99}}  # Score greater than 4.99\n    \n[/code]\n\nMultiple conditions:\n[code] \n    {\n        \"score\": {\"$gte\": 3.0},\n        \"color\": \"red\"\n    }\n    \n[/code]\n\n###  `` `limit: int = 10` `class-attribute` `instance-attribute` \u00b6\n\nMaximum number of items to return in the search results.\n\n###  `` `offset: int = 0` `class-attribute` `instance-attribute` \u00b6\n\nNumber of matching items to skip for pagination.\n\n###  `` `query: Optional[str] = None` `class-attribute` `instance-attribute` \u00b6\n\nNatural language search query for semantic search capabilities.\n\nExamples\n\n  * \"technical documentation about REST APIs\"\n  * \"machine learning papers from 2023\"\n\n\n\n##  `` `MatchCondition` \u00b6\n\nBases: `NamedTuple`\n\nRepresents a pattern for matching namespaces in the store.\n\nThis class combines a match type (prefix or suffix) with a namespace path pattern that can include wildcards to flexibly match different namespace hierarchies.\n\nExamples\n\nPrefix matching: \n[code]\n    MatchCondition(match_type=\"prefix\", path=(\"users\", \"profiles\"))\n    \n[/code]\n\nSuffix matching with wildcard: \n[code]\n    MatchCondition(match_type=\"suffix\", path=(\"cache\", \"*\"))\n    \n[/code]\n\nSimple suffix matching: \n[code]\n    MatchCondition(match_type=\"suffix\", path=(\"v1\",))\n    \n[/code]\n\n###  `` `match_type: NamespaceMatchType` `instance-attribute` \u00b6\n\nType of namespace matching to perform.\n\n###  `` `path: NamespacePath` `instance-attribute` \u00b6\n\nNamespace path pattern that can include wildcards.\n\n##  `` `ListNamespacesOp` \u00b6\n\nBases: `NamedTuple`\n\nOperation to list and filter namespaces in the store.\n\nThis operation allows exploring the organization of data, finding specific collections, and navigating the namespace hierarchy.\n\nExamples\n\nList all namespaces under the \"documents\" path: \n[code]\n    ListNamespacesOp(\n        match_conditions=(MatchCondition(match_type=\"prefix\", path=(\"documents\",)),),\n        max_depth=2\n    )\n    \n[/code]\n\nList all namespaces that end with \"v1\": \n[code]\n    ListNamespacesOp(\n        match_conditions=(MatchCondition(match_type=\"suffix\", path=(\"v1\",)),),\n        limit=50\n    )\n    \n[/code]\n\n###  `` `match_conditions: Optional[tuple[MatchCondition, ...]] = None` `class-attribute` `instance-attribute` \u00b6\n\nOptional conditions for filtering namespaces.\n\nExamples\n\nAll user namespaces: \n[code]\n    (MatchCondition(match_type=\"prefix\", path=(\"users\",)),)\n    \n[/code]\n\nAll namespaces that start with \"docs\" and end with \"draft\": \n[code]\n    (\n        MatchCondition(match_type=\"prefix\", path=(\"docs\",)),\n        MatchCondition(match_type=\"suffix\", path=(\"draft\",))\n    ) \n    \n[/code]\n\n###  `` `max_depth: Optional[int] = None` `class-attribute` `instance-attribute` \u00b6\n\nMaximum depth of namespace hierarchy to return.\n\nNote\n\nNamespaces deeper than this level will be truncated.\n\n###  `` `limit: int = 100` `class-attribute` `instance-attribute` \u00b6\n\nMaximum number of namespaces to return.\n\n###  `` `offset: int = 0` `class-attribute` `instance-attribute` \u00b6\n\nNumber of namespaces to skip for pagination.\n\n##  `` `PutOp` \u00b6\n\nBases: `NamedTuple`\n\nOperation to store, update, or delete an item in the store.\n\nThis class represents a single operation to modify the store's contents, whether adding new items, updating existing ones, or removing them.\n\n###  `` `namespace: tuple[str, ...]` `instance-attribute` \u00b6\n\nHierarchical path that identifies the location of the item.\n\nThe namespace acts as a folder-like structure to organize items. Each element in the tuple represents one level in the hierarchy.\n\nExamples\n\nRoot level documents \n[code]\n    (\"documents\",)\n    \n[/code]\n\nUser-specific documents \n[code]\n    (\"documents\", \"user123\")\n    \n[/code]\n\nNested cache structure \n[code]\n    (\"cache\", \"embeddings\", \"v1\")\n    \n[/code]\n\n###  `` `key: str` `instance-attribute` \u00b6\n\nUnique identifier for the item within its namespace.\n\nThe key must be unique within the specific namespace to avoid conflicts. Together with the namespace, it forms a complete path to the item.\n\nExample\n\nIf namespace is (\"documents\", \"user123\") and key is \"report1\", the full path would effectively be \"documents/user123/report1\"\n\n###  `` `value: Optional[dict[str, Any]]` `instance-attribute` \u00b6\n\nThe data to store, or None to mark the item for deletion.\n\nThe value must be a dictionary with string keys and JSON-serializable values. Setting this to None signals that the item should be deleted.\n\nExample\n\n{ \"field1\": \"string value\", \"field2\": 123, \"nested\": {\"can\": \"contain\", \"any\": \"serializable data\"} }\n\n###  `` `index: Optional[Union[Literal[False], list[str]]] = None` `class-attribute` `instance-attribute` \u00b6\n\nControls how the item's fields are indexed for search operations.\n\nIndexing configuration determines how the item can be found through search\n\n  * None (default): Uses the store's default indexing configuration (if provided)\n  * False: Disables indexing for this item\n  * list[str]: Specifies which json path fields to index for search\n\n\n\nThe item remains accessible through direct get() operations regardless of indexing. When indexed, fields can be searched using natural language queries through vector similarity search (if supported by the store implementation).\n\nPath Syntax\n\n  * Simple field access: \"field\"\n  * Nested fields: \"parent.child.grandchild\"\n  * Array indexing:\n  * Specific index: \"array[0]\"\n  * Last element: \"array[-1]\"\n  * All elements (each individually): \"array[*]\"\n\nExamples\n\n  * None - Use store defaults (whole item)\n  * list[str] - List of fields to index\n\n\n[code] \n    [\n        \"metadata.title\",                    # Nested field access\n        \"context[*].content\",                # Index content from all context as separate vectors\n        \"authors[0].name\",                   # First author's name\n        \"revisions[-1].changes\",             # Most recent revision's changes\n        \"sections[*].paragraphs[*].text\",    # All text from all paragraphs in all sections\n        \"metadata.tags[*]\",                  # All tags in metadata\n    ]\n    \n[/code]\n\n##  `` `InvalidNamespaceError` \u00b6\n\nBases: `ValueError`\n\nProvided namespace is invalid.\n\n##  `` `IndexConfig` \u00b6\n\nBases: `TypedDict`\n\nConfiguration for indexing documents for semantic search in the store.\n\nIf not provided to the store, the store will not support vector search. In that case, all `index` arguments to put() and `aput()` operations will be ignored.\n\n###  `` `dims: int` `instance-attribute` \u00b6\n\nNumber of dimensions in the embedding vectors.\n\nCommon embedding models have the following dimensions\n\n  * openai:text-embedding-3-large: 3072\n  * openai:text-embedding-3-small: 1536\n  * openai:text-embedding-ada-002: 1536\n  * cohere:embed-english-v3.0: 1024\n  * cohere:embed-english-light-v3.0: 384\n  * cohere:embed-multilingual-v3.0: 1024\n  * cohere:embed-multilingual-light-v3.0: 384\n\n\n\n###  `` `embed: Union[Embeddings, EmbeddingsFunc, AEmbeddingsFunc, str]` `instance-attribute` \u00b6\n\nOptional function to generate embeddings from text.\n\nCan be specified in three ways\n\n  1. A LangChain Embeddings instance\n  2. A synchronous embedding function (EmbeddingsFunc)\n  3. An asynchronous embedding function (AEmbeddingsFunc)\n  4. A provider string (e.g., \"openai:text-embedding-3-small\")\n\nExamples\n\nUsing LangChain's initialization with InMemoryStore: \n[code]\n    from langchain.embeddings import init_embeddings\n    from langgraph.store.memory import InMemoryStore\n    \n    store = InMemoryStore(\n        index={\n            \"dims\": 1536,\n            \"embed\": init_embeddings(\"openai:text-embedding-3-small\")\n        }\n    )\n    \n[/code]\n\nUsing a custom embedding function with InMemoryStore: \n[code]\n    from openai import OpenAI\n    from langgraph.store.memory import InMemoryStore\n    \n    client = OpenAI()\n    \n    def embed_texts(texts: list[str]) -> list[list[float]]:\n        response = client.embeddings.create(\n            model=\"text-embedding-3-small\",\n            input=texts\n        )\n        return [e.embedding for e in response.data]\n    \n    store = InMemoryStore(\n        index={\n            \"dims\": 1536,\n            \"embed\": embed_texts\n        }\n    )\n    \n[/code]\n\nUsing an asynchronous embedding function with InMemoryStore: \n[code]\n    from openai import AsyncOpenAI\n    from langgraph.store.memory import InMemoryStore\n    \n    client = AsyncOpenAI()\n    \n    async def aembed_texts(texts: list[str]) -> list[list[float]]:\n        response = await client.embeddings.create(\n            model=\"text-embedding-3-small\",\n            input=texts\n        )\n        return [e.embedding for e in response.data]\n    \n    store = InMemoryStore(\n        index={\n            \"dims\": 1536,\n            \"embed\": aembed_texts\n        }\n    )\n    \n[/code]\n\n###  `` `fields: Optional[list[str]]` `instance-attribute` \u00b6\n\nFields to extract text from for embedding generation.\n\nControls which parts of stored items are embedded for semantic search. Follows JSON path syntax:\n[code] \n    - [\"$\"]: Embeds the entire JSON object as one vector  (default)\n    - [\"field1\", \"field2\"]: Embeds specific top-level fields\n    - [\"parent.child\"]: Embeds nested fields using dot notation\n    - [\"array[*].field\"]: Embeds field from each array element separately\n    \n[/code]\n\nNote\n\nYou can always override this behavior when storing an item using the `index` parameter in the `put` or `aput` operations.\n\nExamples\n[code] \n    # Embed entire document (default)\n    fields=[\"$\"]\n    \n    # Embed specific fields\n    fields=[\"text\", \"summary\"]\n    \n    # Embed nested fields\n    fields=[\"metadata.title\", \"content.body\"]\n    \n    # Embed from arrays\n    fields=[\"messages[*].content\"]  # Each message content separately\n    fields=[\"context[0].text\"]      # First context item's text\n    \n[/code]\n\nNote\n\n  * Fields missing from a document are skipped\n  * Array notation creates separate embeddings for each element\n  * Complex nested paths are supported (e.g., \"a.b[*].c.d\")\n\n\n\n##  `` `BaseStore` \u00b6\n\nBases: `ABC`\n\nAbstract base class for persistent key-value stores.\n\nStores enable persistence and memory that can be shared across threads, scoped to user IDs, assistant IDs, or other arbitrary namespaces. Some implementations may support semantic search capabilities through an optional `index` configuration.\n\nNote\n\nSemantic search capabilities vary by implementation and are typically disabled by default. Stores that support this feature can be configured by providing an `index` configuration at creation time. Without this configuration, semantic search is disabled and any `index` arguments to storage operations will have no effect.\n\n###  `` `batch(ops: Iterable[Op]) -> list[Result]` `abstractmethod` \u00b6\n\nExecute multiple operations synchronously in a single batch.\n\nParameters:\n\n  * **`ops`** (`Iterable[Op]`) \u2013 \n\nAn iterable of operations to execute.\n\n\n\n\nReturns:\n\n  * `list[Result]` \u2013 \n\nA list of results, where each result corresponds to an operation in the input.\n\n  * `list[Result]` \u2013 \n\nThe order of results matches the order of input operations.\n\n\n\n\n###  `` `abatch(ops: Iterable[Op]) -> list[Result]` `abstractmethod` `async` \u00b6\n\nExecute multiple operations asynchronously in a single batch.\n\nParameters:\n\n  * **`ops`** (`Iterable[Op]`) \u2013 \n\nAn iterable of operations to execute.\n\n\n\n\nReturns:\n\n  * `list[Result]` \u2013 \n\nA list of results, where each result corresponds to an operation in the input.\n\n  * `list[Result]` \u2013 \n\nThe order of results matches the order of input operations.\n\n\n\n\n###  `` `get(namespace: tuple[str, ...], key: str) -> Optional[Item]` \u00b6\n\nRetrieve a single item.\n\nParameters:\n\n  * **`namespace`** (`tuple[str, ...]`) \u2013 \n\nHierarchical path for the item.\n\n  * **`key`** (`str`) \u2013 \n\nUnique identifier within the namespace.\n\n\n\n\nReturns:\n\n  * `Optional[Item]` \u2013 \n\nThe retrieved item or None if not found.\n\n\n\n\n###  `` `search(namespace_prefix: tuple[str, ...], /, *, query: Optional[str] = None, filter: Optional[dict[str, Any]] = None, limit: int = 10, offset: int = 0) -> list[SearchItem]` \u00b6\n\nSearch for items within a namespace prefix.\n\nParameters:\n\n  * **`namespace_prefix`** (`tuple[str, ...]`) \u2013 \n\nHierarchical path prefix to search within.\n\n  * **`query`** (`Optional[str]`, default: `None` ) \u2013 \n\nOptional query for natural language search.\n\n  * **`filter`** (`Optional[dict[str, Any]]`, default: `None` ) \u2013 \n\nKey-value pairs to filter results.\n\n  * **`limit`** (`int`, default: `10` ) \u2013 \n\nMaximum number of items to return.\n\n  * **`offset`** (`int`, default: `0` ) \u2013 \n\nNumber of items to skip before returning results.\n\n\n\n\nReturns:\n\n  * `list[SearchItem]` \u2013 \n\nList of items matching the search criteria.\n\n\nExamples\n\nBasic filtering: \n[code]\n    # Search for documents with specific metadata\n    results = store.search(\n        (\"docs\",),\n        filter={\"type\": \"article\", \"status\": \"published\"}\n    )\n    \n[/code]\n\nNatural language search (requires vector store implementation): \n[code]\n    # Initialize store with embedding configuration\n    store = YourStore( # e.g., InMemoryStore, AsyncPostgresStore\n        index={\n            \"dims\": 1536,  # embedding dimensions\n            \"embed\": your_embedding_function,  # function to create embeddings\n            \"fields\": [\"text\"]  # fields to embed. Defaults to [\"$\"]\n        }\n    )\n    \n    # Search for semantically similar documents\n    results = store.search(\n        (\"docs\",),\n        query=\"machine learning applications in healthcare\",\n        filter={\"type\": \"research_paper\"},\n        limit=5\n    )\n    \n[/code]\n\nNote: Natural language search support depends on your store implementation and requires proper embedding configuration.\n\n###  `` `put(namespace: tuple[str, ...], key: str, value: dict[str, Any], index: Optional[Union[Literal[False], list[str]]] = None) -> None` \u00b6\n\nStore or update an item in the store.\n\nParameters:\n\n  * **`namespace`** (`tuple[str, ...]`) \u2013 \n\nHierarchical path for the item, represented as a tuple of strings. Example: (\"documents\", \"user123\")\n\n  * **`key`** (`str`) \u2013 \n\nUnique identifier within the namespace. Together with namespace forms the complete path to the item.\n\n  * **`value`** (`dict[str, Any]`) \u2013 \n\nDictionary containing the item's data. Must contain string keys and JSON-serializable values.\n\n  * **`index`** (`Optional[Union[Literal[False], list[str]]]`, default: `None` ) \u2013 \n\nControls how the item's fields are indexed for search:\n\n    * None (default): Use `fields` you configured when creating the store (if any) If you do not initialize the store with indexing capabilities, the `index` parameter will be ignored\n    * False: Disable indexing for this item\n    * list[str]: List of field paths to index, supporting:\n      * Nested fields: \"metadata.title\"\n      * Array access: \"chapters[*].content\" (each indexed separately)\n      * Specific indices: \"authors[0].name\"\n\n\nNote\n\nIndexing support depends on your store implementation. If you do not initialize the store with indexing capabilities, the `index` parameter will be ignored.\n\nExamples\n\nStore item. Indexing depends on how you configure the store. \n[code]\n    store.put((\"docs\",), \"report\", {\"memory\": \"Will likes ai\"})\n    \n[/code]\n\nDo not index item for semantic search. Still accessible through get() and search() operations but won't have a vector representation. \n[code]\n    store.put((\"docs\",), \"report\", {\"memory\": \"Will likes ai\"}, index=False)\n    \n[/code]\n\nIndex specific fields for search. \n[code]\n    store.put((\"docs\",), \"report\", {\"memory\": \"Will likes ai\"}, index=[\"memory\"])\n    \n[/code]\n\n###  `` `delete(namespace: tuple[str, ...], key: str) -> None` \u00b6\n\nDelete an item.\n\nParameters:\n\n  * **`namespace`** (`tuple[str, ...]`) \u2013 \n\nHierarchical path for the item.\n\n  * **`key`** (`str`) \u2013 \n\nUnique identifier within the namespace.\n\n\n\n\n###  `` `list_namespaces(*, prefix: Optional[NamespacePath] = None, suffix: Optional[NamespacePath] = None, max_depth: Optional[int] = None, limit: int = 100, offset: int = 0) -> list[tuple[str, ...]]` \u00b6\n\nList and filter namespaces in the store.\n\nUsed to explore the organization of data, find specific collections, or navigate the namespace hierarchy.\n\nParameters:\n\n  * **`prefix`** (`Optional[Tuple[str, ...]]`, default: `None` ) \u2013 \n\nFilter namespaces that start with this path.\n\n  * **`suffix`** (`Optional[Tuple[str, ...]]`, default: `None` ) \u2013 \n\nFilter namespaces that end with this path.\n\n  * **`max_depth`** (`Optional[int]`, default: `None` ) \u2013 \n\nReturn namespaces up to this depth in the hierarchy. Namespaces deeper than this level will be truncated.\n\n  * **`limit`** (`int`, default: `100` ) \u2013 \n\nMaximum number of namespaces to return (default 100).\n\n  * **`offset`** (`int`, default: `0` ) \u2013 \n\nNumber of namespaces to skip for pagination (default 0).\n\n\n\n\nReturns:\n\n  * `list[tuple[str, ...]]` \u2013 \n\nList[Tuple[str, ...]]: A list of namespace tuples that match the criteria.\n\n  * `list[tuple[str, ...]]` \u2013 \n\nEach tuple represents a full namespace path up to `max_depth`.\n\n\n\n\n???+ example \"Examples\": Setting max_depth=3. Given the namespaces: \n[code]\n    # Example if you have the following namespaces:\n    # (\"a\", \"b\", \"c\")\n    # (\"a\", \"b\", \"d\", \"e\")\n    # (\"a\", \"b\", \"d\", \"i\")\n    # (\"a\", \"b\", \"f\")\n    # (\"a\", \"c\", \"f\")\n    store.list_namespaces(prefix=(\"a\", \"b\"), max_depth=3)\n    # [(\"a\", \"b\", \"c\"), (\"a\", \"b\", \"d\"), (\"a\", \"b\", \"f\")]\n    \n[/code]\n\n###  `` `aget(namespace: tuple[str, ...], key: str) -> Optional[Item]` `async` \u00b6\n\nAsynchronously retrieve a single item.\n\nParameters:\n\n  * **`namespace`** (`tuple[str, ...]`) \u2013 \n\nHierarchical path for the item.\n\n  * **`key`** (`str`) \u2013 \n\nUnique identifier within the namespace.\n\n\n\n\nReturns:\n\n  * `Optional[Item]` \u2013 \n\nThe retrieved item or None if not found.\n\n\n\n\n###  `` `asearch(namespace_prefix: tuple[str, ...], /, *, query: Optional[str] = None, filter: Optional[dict[str, Any]] = None, limit: int = 10, offset: int = 0) -> list[SearchItem]` `async` \u00b6\n\nAsynchronously search for items within a namespace prefix.\n\nParameters:\n\n  * **`namespace_prefix`** (`tuple[str, ...]`) \u2013 \n\nHierarchical path prefix to search within.\n\n  * **`query`** (`Optional[str]`, default: `None` ) \u2013 \n\nOptional query for natural language search.\n\n  * **`filter`** (`Optional[dict[str, Any]]`, default: `None` ) \u2013 \n\nKey-value pairs to filter results.\n\n  * **`limit`** (`int`, default: `10` ) \u2013 \n\nMaximum number of items to return.\n\n  * **`offset`** (`int`, default: `0` ) \u2013 \n\nNumber of items to skip before returning results.\n\n\n\n\nReturns:\n\n  * `list[SearchItem]` \u2013 \n\nList of items matching the search criteria.\n\n\nExamples\n\nBasic filtering: \n[code]\n    # Search for documents with specific metadata\n    results = await store.asearch(\n        (\"docs\",),\n        filter={\"type\": \"article\", \"status\": \"published\"}\n    )\n    \n[/code]\n\nNatural language search (requires vector store implementation): \n[code]\n    # Initialize store with embedding configuration\n    store = YourStore( # e.g., InMemoryStore, AsyncPostgresStore\n        index={\n            \"dims\": 1536,  # embedding dimensions\n            \"embed\": your_embedding_function,  # function to create embeddings\n            \"fields\": [\"text\"]  # fields to embed\n        }\n    )\n    \n    # Search for semantically similar documents\n    results = await store.asearch(\n        (\"docs\",),\n        query=\"machine learning applications in healthcare\",\n        filter={\"type\": \"research_paper\"},\n        limit=5\n    )\n    \n[/code]\n\nNote: Natural language search support depends on your store implementation and requires proper embedding configuration.\n\n###  `` `aput(namespace: tuple[str, ...], key: str, value: dict[str, Any], index: Optional[Union[Literal[False], list[str]]] = None) -> None` `async` \u00b6\n\nAsynchronously store or update an item in the store.\n\nParameters:\n\n  * **`namespace`** (`tuple[str, ...]`) \u2013 \n\nHierarchical path for the item, represented as a tuple of strings. Example: (\"documents\", \"user123\")\n\n  * **`key`** (`str`) \u2013 \n\nUnique identifier within the namespace. Together with namespace forms the complete path to the item.\n\n  * **`value`** (`dict[str, Any]`) \u2013 \n\nDictionary containing the item's data. Must contain string keys and JSON-serializable values.\n\n  * **`index`** (`Optional[Union[Literal[False], list[str]]]`, default: `None` ) \u2013 \n\nControls how the item's fields are indexed for search:\n\n    * None (default): Use `fields` you configured when creating the store (if any) If you do not initialize the store with indexing capabilities, the `index` parameter will be ignored\n    * False: Disable indexing for this item\n    * list[str]: List of field paths to index, supporting:\n      * Nested fields: \"metadata.title\"\n      * Array access: \"chapters[*].content\" (each indexed separately)\n      * Specific indices: \"authors[0].name\"\n\n\nNote\n\nIndexing support depends on your store implementation. If you do not initialize the store with indexing capabilities, the `index` parameter will be ignored.\n\nExamples\n\nStore item. Indexing depends on how you configure the store. \n[code]\n    await store.aput((\"docs\",), \"report\", {\"memory\": \"Will likes ai\"})\n    \n[/code]\n\nDo not index item for semantic search. Still accessible through get() and search() operations but won't have a vector representation. \n[code]\n    await store.aput((\"docs\",), \"report\", {\"memory\": \"Will likes ai\"}, index=False)\n    \n[/code]\n\nIndex specific fields for search (if store configured to index items): \n[code]\n    await store.aput(\n        (\"docs\",),\n        \"report\",\n        {\n            \"memory\": \"Will likes ai\",\n            \"context\": [{\"content\": \"...\"}, {\"content\": \"...\"}]\n        },\n        index=[\"memory\", \"context[*].content\"]\n    )\n    \n[/code]\n\n###  `` `adelete(namespace: tuple[str, ...], key: str) -> None` `async` \u00b6\n\nAsynchronously delete an item.\n\nParameters:\n\n  * **`namespace`** (`tuple[str, ...]`) \u2013 \n\nHierarchical path for the item.\n\n  * **`key`** (`str`) \u2013 \n\nUnique identifier within the namespace.\n\n\n\n\n###  `` `alist_namespaces(*, prefix: Optional[NamespacePath] = None, suffix: Optional[NamespacePath] = None, max_depth: Optional[int] = None, limit: int = 100, offset: int = 0) -> list[tuple[str, ...]]` `async` \u00b6\n\nList and filter namespaces in the store asynchronously.\n\nUsed to explore the organization of data, find specific collections, or navigate the namespace hierarchy.\n\nParameters:\n\n  * **`prefix`** (`Optional[Tuple[str, ...]]`, default: `None` ) \u2013 \n\nFilter namespaces that start with this path.\n\n  * **`suffix`** (`Optional[Tuple[str, ...]]`, default: `None` ) \u2013 \n\nFilter namespaces that end with this path.\n\n  * **`max_depth`** (`Optional[int]`, default: `None` ) \u2013 \n\nReturn namespaces up to this depth in the hierarchy. Namespaces deeper than this level will be truncated to this depth.\n\n  * **`limit`** (`int`, default: `100` ) \u2013 \n\nMaximum number of namespaces to return (default 100).\n\n  * **`offset`** (`int`, default: `0` ) \u2013 \n\nNumber of namespaces to skip for pagination (default 0).\n\n\n\n\nReturns:\n\n  * `list[tuple[str, ...]]` \u2013 \n\nList[Tuple[str, ...]]: A list of namespace tuples that match the criteria.\n\n  * `list[tuple[str, ...]]` \u2013 \n\nEach tuple represents a full namespace path up to `max_depth`.\n\n\nExamples\n\nSetting max_depth=3 with existing namespaces: \n[code]\n    # Given the following namespaces:\n    # (\"a\", \"b\", \"c\")\n    # (\"a\", \"b\", \"d\", \"e\")\n    # (\"a\", \"b\", \"d\", \"i\")\n    # (\"a\", \"b\", \"f\")\n    # (\"a\", \"c\", \"f\")\n    \n    await store.alist_namespaces(prefix=(\"a\", \"b\"), max_depth=3)\n    # Returns: [(\"a\", \"b\", \"c\"), (\"a\", \"b\", \"d\"), (\"a\", \"b\", \"f\")]\n    \n[/code]\n\n##  `` `ensure_embeddings(embed: Union[Embeddings, EmbeddingsFunc, AEmbeddingsFunc, str, None]) -> Embeddings` \u00b6\n\nEnsure that an embedding function conforms to LangChain's Embeddings interface.\n\nThis function wraps arbitrary embedding functions to make them compatible with LangChain's Embeddings interface. It handles both synchronous and asynchronous functions.\n\nParameters:\n\n  * **`embed`** (`Union[Embeddings, EmbeddingsFunc, AEmbeddingsFunc, str, None]`) \u2013 \n\nEither an existing Embeddings instance, or a function that converts text to embeddings. If the function is async, it will be used for both sync and async operations.\n\n\n\n\nReturns:\n\n  * `Embeddings` \u2013 \n\nAn Embeddings instance that wraps the provided function(s).\n\n\nExamples\n\nWrap a synchronous embedding function: \n[code]\n    def my_embed_fn(texts):\n        return [[0.1, 0.2] for _ in texts]\n    \n    embeddings = ensure_embeddings(my_embed_fn)\n    result = embeddings.embed_query(\"hello\")  # Returns [0.1, 0.2]\n    \n[/code]\n\nWrap an asynchronous embedding function: \n[code]\n    async def my_async_fn(texts):\n        return [[0.1, 0.2] for _ in texts]\n    \n    embeddings = ensure_embeddings(my_async_fn)\n    result = await embeddings.aembed_query(\"hello\")  # Returns [0.1, 0.2]\n    \n[/code]\n\nInitialize embeddings using a provider string: \n[code]\n    # Requires langchain>=0.3.9 and langgraph-checkpoint>=2.0.11\n    embeddings = ensure_embeddings(\"openai:text-embedding-3-small\")\n    result = embeddings.embed_query(\"hello\")\n    \n[/code]\n\n##  `` `get_text_at_path(obj: Any, path: Union[str, list[str]]) -> list[str]` \u00b6\n\nExtract text from an object using a path expression or pre-tokenized path.\n\nParameters:\n\n  * **`obj`** (`Any`) \u2013 \n\nThe object to extract text from\n\n  * **`path`** (`Union[str, list[str]]`) \u2013 \n\nEither a path string or pre-tokenized path list.\n\n\n\n\nPath types handled\n\n  * Simple paths: \"field1.field2\"\n  * Array indexing: \"[0]\", \"[*]\", \"[-1]\"\n  * Wildcards: \"*\"\n  * Multi-field selection: \"{field1,field2}\"\n  * Nested paths in multi-field: \"{field1,nested.field2}\"\n\n\n\n##  `` `tokenize_path(path: str) -> list[str]` \u00b6\n\nTokenize a path into components.\n\nTypes handled\n\n  * Simple paths: \"field1.field2\"\n  * Array indexing: \"[0]\", \"[*]\", \"[-1]\"\n  * Wildcards: \"*\"\n  * Multi-field selection: \"{field1,field2}\"\n\n\n\n##  `` `AsyncPostgresStore` \u00b6\n\nBases: `AsyncBatchedBaseStore`, `BasePostgresStore[Conn]`\n\nAsynchronous Postgres-backed store with optional vector search using pgvector.\n\nExamples\n\nBasic setup and usage: \n[code]\n    from langgraph.store.postgres import AsyncPostgresStore\n    \n    conn_string = \"postgresql://user:pass@localhost:5432/dbname\"\n    \n    async with AsyncPostgresStore.from_conn_string(conn_string) as store:\n        await store.setup()  # Run migrations. Done once\n    \n        # Store and retrieve data\n        await store.aput((\"users\", \"123\"), \"prefs\", {\"theme\": \"dark\"})\n        item = await store.aget((\"users\", \"123\"), \"prefs\")\n    \n[/code]\n\nVector search using LangChain embeddings: \n[code]\n    from langchain.embeddings import init_embeddings\n    from langgraph.store.postgres import AsyncPostgresStore\n    \n    conn_string = \"postgresql://user:pass@localhost:5432/dbname\"\n    \n    async with AsyncPostgresStore.from_conn_string(\n        conn_string,\n        index={\n            \"dims\": 1536,\n            \"embed\": init_embeddings(\"openai:text-embedding-3-small\"),\n            \"fields\": [\"text\"]  # specify which fields to embed. Default is the whole serialized value\n        }\n    ) as store:\n        await store.setup()  # Run migrations. Done once\n    \n        # Store documents\n        await store.aput((\"docs\",), \"doc1\", {\"text\": \"Python tutorial\"})\n        await store.aput((\"docs\",), \"doc2\", {\"text\": \"TypeScript guide\"})\n        await store.aput((\"docs\",), \"doc3\", {\"text\": \"Other guide\"}, index=False)  # don't index\n    \n        # Search by similarity\n        results = await store.asearch((\"docs\",), \"programming guides\", limit=2)\n    \n[/code]\n\nUsing connection pooling for better performance: \n[code]\n    from langgraph.store.postgres import AsyncPostgresStore, PoolConfig\n    \n    conn_string = \"postgresql://user:pass@localhost:5432/dbname\"\n    \n    async with AsyncPostgresStore.from_conn_string(\n        conn_string,\n        pool_config=PoolConfig(\n            min_size=5,\n            max_size=20\n        )\n    ) as store:\n        await store.setup()  # Run migrations. Done once\n        # Use store with connection pooling...\n    \n[/code]\n\nWarning\n\nMake sure to: 1\\. Call `setup()` before first use to create necessary tables and indexes 2\\. Have the pgvector extension available to use vector search 3\\. Use Python 3.10+ for async functionality\n\nNote\n\nSemantic search is disabled by default. You can enable it by providing an `index` configuration when creating the store. Without this configuration, all `index` arguments passed to `put` or `aput` will have no effect.\n\n###  `` `from_conn_string(conn_string: str, *, pipeline: bool = False, pool_config: Optional[PoolConfig] = None, index: Optional[PostgresIndexConfig] = None) -> AsyncIterator[AsyncPostgresStore]` `async` `classmethod` \u00b6\n\nCreate a new AsyncPostgresStore instance from a connection string.\n\nParameters:\n\n  * **`conn_string`** (`str`) \u2013 \n\nThe Postgres connection info string.\n\n  * **`pipeline`** (`bool`, default: `False` ) \u2013 \n\nWhether to use AsyncPipeline (only for single connections)\n\n  * **`pool_config`** (`Optional[PoolConfig]`, default: `None` ) \u2013 \n\nConfiguration for the connection pool. If provided, will create a connection pool and use it instead of a single connection. This overrides the `pipeline` argument.\n\n  * **`index`** (`Optional[PostgresIndexConfig]`, default: `None` ) \u2013 \n\nThe embedding config.\n\n\n\n\nReturns:\n\n  * **`AsyncPostgresStore`** ( `AsyncIterator[AsyncPostgresStore]` ) \u2013 \n\nA new AsyncPostgresStore instance.\n\n\n\n\n###  `` `setup() -> None` `async` \u00b6\n\nSet up the store database asynchronously.\n\nThis method creates the necessary tables in the Postgres database if they don't already exist and runs database migrations. It MUST be called directly by the user the first time the store is used.\n\n##  `` `PostgresStore` \u00b6\n\nBases: `BaseStore`, `BasePostgresStore[Conn]`\n\nPostgres-backed store with optional vector search using pgvector.\n\nExamples\n\nBasic setup and usage: \n[code]\n    from langgraph.store.postgres import PostgresStore\n    from psycopg import Connection\n    \n    conn_string = \"postgresql://user:pass@localhost:5432/dbname\"\n    \n    # Using direct connection\n    with Connection.connect(conn_string) as conn:\n        store = PostgresStore(conn)\n        store.setup() # Run migrations. Done once\n    \n        # Store and retrieve data\n        store.put((\"users\", \"123\"), \"prefs\", {\"theme\": \"dark\"})\n        item = store.get((\"users\", \"123\"), \"prefs\")\n    \n[/code]\n\nOr using the convenient from_conn_string helper: \n[code]\n    from langgraph.store.postgres import PostgresStore\n    \n    conn_string = \"postgresql://user:pass@localhost:5432/dbname\"\n    \n    with PostgresStore.from_conn_string(conn_string) as store:\n        store.setup()\n    \n        # Store and retrieve data\n        store.put((\"users\", \"123\"), \"prefs\", {\"theme\": \"dark\"})\n        item = store.get((\"users\", \"123\"), \"prefs\")\n    \n[/code]\n\nVector search using LangChain embeddings: \n[code]\n    from langchain.embeddings import init_embeddings\n    from langgraph.store.postgres import PostgresStore\n    \n    conn_string = \"postgresql://user:pass@localhost:5432/dbname\"\n    \n    with PostgresStore.from_conn_string(\n        conn_string,\n        index={\n            \"dims\": 1536,\n            \"embed\": init_embeddings(\"openai:text-embedding-3-small\"),\n            \"fields\": [\"text\"]  # specify which fields to embed. Default is the whole serialized value\n        }\n    ) as store:\n        store.setup() # Do this once to run migrations\n    \n        # Store documents\n        store.put((\"docs\",), \"doc1\", {\"text\": \"Python tutorial\"})\n        store.put((\"docs\",), \"doc2\", {\"text\": \"TypeScript guide\"})\n        store.put((\"docs\",), \"doc2\", {\"text\": \"Other guide\"}, index=False) # don't index\n    \n        # Search by similarity\n        results = store.search((\"docs\",), \"programming guides\", limit=2)\n    \n[/code]\n\nNote\n\nSemantic search is disabled by default. You can enable it by providing an `index` configuration when creating the store. Without this configuration, all `index` arguments passed to `put` or `aput`will have no effect.\n\nWarning\n\nMake sure to call `setup()` before first use to create necessary tables and indexes. The pgvector extension must be available to use vector search.\n\n###  `` `get(namespace: tuple[str, ...], key: str) -> Optional[Item]` \u00b6\n\nRetrieve a single item.\n\nParameters:\n\n  * **`namespace`** (`tuple[str, ...]`) \u2013 \n\nHierarchical path for the item.\n\n  * **`key`** (`str`) \u2013 \n\nUnique identifier within the namespace.\n\n\n\n\nReturns:\n\n  * `Optional[Item]` \u2013 \n\nThe retrieved item or None if not found.\n\n\n\n\n###  `` `search(namespace_prefix: tuple[str, ...], /, *, query: Optional[str] = None, filter: Optional[dict[str, Any]] = None, limit: int = 10, offset: int = 0) -> list[SearchItem]` \u00b6\n\nSearch for items within a namespace prefix.\n\nParameters:\n\n  * **`namespace_prefix`** (`tuple[str, ...]`) \u2013 \n\nHierarchical path prefix to search within.\n\n  * **`query`** (`Optional[str]`, default: `None` ) \u2013 \n\nOptional query for natural language search.\n\n  * **`filter`** (`Optional[dict[str, Any]]`, default: `None` ) \u2013 \n\nKey-value pairs to filter results.\n\n  * **`limit`** (`int`, default: `10` ) \u2013 \n\nMaximum number of items to return.\n\n  * **`offset`** (`int`, default: `0` ) \u2013 \n\nNumber of items to skip before returning results.\n\n\n\n\nReturns:\n\n  * `list[SearchItem]` \u2013 \n\nList of items matching the search criteria.\n\n\nExamples\n\nBasic filtering: \n[code]\n    # Search for documents with specific metadata\n    results = store.search(\n        (\"docs\",),\n        filter={\"type\": \"article\", \"status\": \"published\"}\n    )\n    \n[/code]\n\nNatural language search (requires vector store implementation): \n[code]\n    # Initialize store with embedding configuration\n    store = YourStore( # e.g., InMemoryStore, AsyncPostgresStore\n        index={\n            \"dims\": 1536,  # embedding dimensions\n            \"embed\": your_embedding_function,  # function to create embeddings\n            \"fields\": [\"text\"]  # fields to embed. Defaults to [\"$\"]\n        }\n    )\n    \n    # Search for semantically similar documents\n    results = store.search(\n        (\"docs\",),\n        query=\"machine learning applications in healthcare\",\n        filter={\"type\": \"research_paper\"},\n        limit=5\n    )\n    \n[/code]\n\nNote: Natural language search support depends on your store implementation and requires proper embedding configuration.\n\n###  `` `put(namespace: tuple[str, ...], key: str, value: dict[str, Any], index: Optional[Union[Literal[False], list[str]]] = None) -> None` \u00b6\n\nStore or update an item in the store.\n\nParameters:\n\n  * **`namespace`** (`tuple[str, ...]`) \u2013 \n\nHierarchical path for the item, represented as a tuple of strings. Example: (\"documents\", \"user123\")\n\n  * **`key`** (`str`) \u2013 \n\nUnique identifier within the namespace. Together with namespace forms the complete path to the item.\n\n  * **`value`** (`dict[str, Any]`) \u2013 \n\nDictionary containing the item's data. Must contain string keys and JSON-serializable values.\n\n  * **`index`** (`Optional[Union[Literal[False], list[str]]]`, default: `None` ) \u2013 \n\nControls how the item's fields are indexed for search:\n\n    * None (default): Use `fields` you configured when creating the store (if any) If you do not initialize the store with indexing capabilities, the `index` parameter will be ignored\n    * False: Disable indexing for this item\n    * list[str]: List of field paths to index, supporting:\n      * Nested fields: \"metadata.title\"\n      * Array access: \"chapters[*].content\" (each indexed separately)\n      * Specific indices: \"authors[0].name\"\n\n\nNote\n\nIndexing support depends on your store implementation. If you do not initialize the store with indexing capabilities, the `index` parameter will be ignored.\n\nExamples\n\nStore item. Indexing depends on how you configure the store. \n[code]\n    store.put((\"docs\",), \"report\", {\"memory\": \"Will likes ai\"})\n    \n[/code]\n\nDo not index item for semantic search. Still accessible through get() and search() operations but won't have a vector representation. \n[code]\n    store.put((\"docs\",), \"report\", {\"memory\": \"Will likes ai\"}, index=False)\n    \n[/code]\n\nIndex specific fields for search. \n[code]\n    store.put((\"docs\",), \"report\", {\"memory\": \"Will likes ai\"}, index=[\"memory\"])\n    \n[/code]\n\n###  `` `delete(namespace: tuple[str, ...], key: str) -> None` \u00b6\n\nDelete an item.\n\nParameters:\n\n  * **`namespace`** (`tuple[str, ...]`) \u2013 \n\nHierarchical path for the item.\n\n  * **`key`** (`str`) \u2013 \n\nUnique identifier within the namespace.\n\n\n\n\n###  `` `list_namespaces(*, prefix: Optional[NamespacePath] = None, suffix: Optional[NamespacePath] = None, max_depth: Optional[int] = None, limit: int = 100, offset: int = 0) -> list[tuple[str, ...]]` \u00b6\n\nList and filter namespaces in the store.\n\nUsed to explore the organization of data, find specific collections, or navigate the namespace hierarchy.\n\nParameters:\n\n  * **`prefix`** (`Optional[Tuple[str, ...]]`, default: `None` ) \u2013 \n\nFilter namespaces that start with this path.\n\n  * **`suffix`** (`Optional[Tuple[str, ...]]`, default: `None` ) \u2013 \n\nFilter namespaces that end with this path.\n\n  * **`max_depth`** (`Optional[int]`, default: `None` ) \u2013 \n\nReturn namespaces up to this depth in the hierarchy. Namespaces deeper than this level will be truncated.\n\n  * **`limit`** (`int`, default: `100` ) \u2013 \n\nMaximum number of namespaces to return (default 100).\n\n  * **`offset`** (`int`, default: `0` ) \u2013 \n\nNumber of namespaces to skip for pagination (default 0).\n\n\n\n\nReturns:\n\n  * `list[tuple[str, ...]]` \u2013 \n\nList[Tuple[str, ...]]: A list of namespace tuples that match the criteria.\n\n  * `list[tuple[str, ...]]` \u2013 \n\nEach tuple represents a full namespace path up to `max_depth`.\n\n\n\n\n???+ example \"Examples\": Setting max_depth=3. Given the namespaces: \n[code]\n    # Example if you have the following namespaces:\n    # (\"a\", \"b\", \"c\")\n    # (\"a\", \"b\", \"d\", \"e\")\n    # (\"a\", \"b\", \"d\", \"i\")\n    # (\"a\", \"b\", \"f\")\n    # (\"a\", \"c\", \"f\")\n    store.list_namespaces(prefix=(\"a\", \"b\"), max_depth=3)\n    # [(\"a\", \"b\", \"c\"), (\"a\", \"b\", \"d\"), (\"a\", \"b\", \"f\")]\n    \n[/code]\n\n###  `` `aget(namespace: tuple[str, ...], key: str) -> Optional[Item]` `async` \u00b6\n\nAsynchronously retrieve a single item.\n\nParameters:\n\n  * **`namespace`** (`tuple[str, ...]`) \u2013 \n\nHierarchical path for the item.\n\n  * **`key`** (`str`) \u2013 \n\nUnique identifier within the namespace.\n\n\n\n\nReturns:\n\n  * `Optional[Item]` \u2013 \n\nThe retrieved item or None if not found.\n\n\n\n\n###  `` `asearch(namespace_prefix: tuple[str, ...], /, *, query: Optional[str] = None, filter: Optional[dict[str, Any]] = None, limit: int = 10, offset: int = 0) -> list[SearchItem]` `async` \u00b6\n\nAsynchronously search for items within a namespace prefix.\n\nParameters:\n\n  * **`namespace_prefix`** (`tuple[str, ...]`) \u2013 \n\nHierarchical path prefix to search within.\n\n  * **`query`** (`Optional[str]`, default: `None` ) \u2013 \n\nOptional query for natural language search.\n\n  * **`filter`** (`Optional[dict[str, Any]]`, default: `None` ) \u2013 \n\nKey-value pairs to filter results.\n\n  * **`limit`** (`int`, default: `10` ) \u2013 \n\nMaximum number of items to return.\n\n  * **`offset`** (`int`, default: `0` ) \u2013 \n\nNumber of items to skip before returning results.\n\n\n\n\nReturns:\n\n  * `list[SearchItem]` \u2013 \n\nList of items matching the search criteria.\n\n\nExamples\n\nBasic filtering: \n[code]\n    # Search for documents with specific metadata\n    results = await store.asearch(\n        (\"docs\",),\n        filter={\"type\": \"article\", \"status\": \"published\"}\n    )\n    \n[/code]\n\nNatural language search (requires vector store implementation): \n[code]\n    # Initialize store with embedding configuration\n    store = YourStore( # e.g., InMemoryStore, AsyncPostgresStore\n        index={\n            \"dims\": 1536,  # embedding dimensions\n            \"embed\": your_embedding_function,  # function to create embeddings\n            \"fields\": [\"text\"]  # fields to embed\n        }\n    )\n    \n    # Search for semantically similar documents\n    results = await store.asearch(\n        (\"docs\",),\n        query=\"machine learning applications in healthcare\",\n        filter={\"type\": \"research_paper\"},\n        limit=5\n    )\n    \n[/code]\n\nNote: Natural language search support depends on your store implementation and requires proper embedding configuration.\n\n###  `` `aput(namespace: tuple[str, ...], key: str, value: dict[str, Any], index: Optional[Union[Literal[False], list[str]]] = None) -> None` `async` \u00b6\n\nAsynchronously store or update an item in the store.\n\nParameters:\n\n  * **`namespace`** (`tuple[str, ...]`) \u2013 \n\nHierarchical path for the item, represented as a tuple of strings. Example: (\"documents\", \"user123\")\n\n  * **`key`** (`str`) \u2013 \n\nUnique identifier within the namespace. Together with namespace forms the complete path to the item.\n\n  * **`value`** (`dict[str, Any]`) \u2013 \n\nDictionary containing the item's data. Must contain string keys and JSON-serializable values.\n\n  * **`index`** (`Optional[Union[Literal[False], list[str]]]`, default: `None` ) \u2013 \n\nControls how the item's fields are indexed for search:\n\n    * None (default): Use `fields` you configured when creating the store (if any) If you do not initialize the store with indexing capabilities, the `index` parameter will be ignored\n    * False: Disable indexing for this item\n    * list[str]: List of field paths to index, supporting:\n      * Nested fields: \"metadata.title\"\n      * Array access: \"chapters[*].content\" (each indexed separately)\n      * Specific indices: \"authors[0].name\"\n\n\nNote\n\nIndexing support depends on your store implementation. If you do not initialize the store with indexing capabilities, the `index` parameter will be ignored.\n\nExamples\n\nStore item. Indexing depends on how you configure the store. \n[code]\n    await store.aput((\"docs\",), \"report\", {\"memory\": \"Will likes ai\"})\n    \n[/code]\n\nDo not index item for semantic search. Still accessible through get() and search() operations but won't have a vector representation. \n[code]\n    await store.aput((\"docs\",), \"report\", {\"memory\": \"Will likes ai\"}, index=False)\n    \n[/code]\n\nIndex specific fields for search (if store configured to index items): \n[code]\n    await store.aput(\n        (\"docs\",),\n        \"report\",\n        {\n            \"memory\": \"Will likes ai\",\n            \"context\": [{\"content\": \"...\"}, {\"content\": \"...\"}]\n        },\n        index=[\"memory\", \"context[*].content\"]\n    )\n    \n[/code]\n\n###  `` `adelete(namespace: tuple[str, ...], key: str) -> None` `async` \u00b6\n\nAsynchronously delete an item.\n\nParameters:\n\n  * **`namespace`** (`tuple[str, ...]`) \u2013 \n\nHierarchical path for the item.\n\n  * **`key`** (`str`) \u2013 \n\nUnique identifier within the namespace.\n\n\n\n\n###  `` `alist_namespaces(*, prefix: Optional[NamespacePath] = None, suffix: Optional[NamespacePath] = None, max_depth: Optional[int] = None, limit: int = 100, offset: int = 0) -> list[tuple[str, ...]]` `async` \u00b6\n\nList and filter namespaces in the store asynchronously.\n\nUsed to explore the organization of data, find specific collections, or navigate the namespace hierarchy.\n\nParameters:\n\n  * **`prefix`** (`Optional[Tuple[str, ...]]`, default: `None` ) \u2013 \n\nFilter namespaces that start with this path.\n\n  * **`suffix`** (`Optional[Tuple[str, ...]]`, default: `None` ) \u2013 \n\nFilter namespaces that end with this path.\n\n  * **`max_depth`** (`Optional[int]`, default: `None` ) \u2013 \n\nReturn namespaces up to this depth in the hierarchy. Namespaces deeper than this level will be truncated to this depth.\n\n  * **`limit`** (`int`, default: `100` ) \u2013 \n\nMaximum number of namespaces to return (default 100).\n\n  * **`offset`** (`int`, default: `0` ) \u2013 \n\nNumber of namespaces to skip for pagination (default 0).\n\n\n\n\nReturns:\n\n  * `list[tuple[str, ...]]` \u2013 \n\nList[Tuple[str, ...]]: A list of namespace tuples that match the criteria.\n\n  * `list[tuple[str, ...]]` \u2013 \n\nEach tuple represents a full namespace path up to `max_depth`.\n\n\nExamples\n\nSetting max_depth=3 with existing namespaces: \n[code]\n    # Given the following namespaces:\n    # (\"a\", \"b\", \"c\")\n    # (\"a\", \"b\", \"d\", \"e\")\n    # (\"a\", \"b\", \"d\", \"i\")\n    # (\"a\", \"b\", \"f\")\n    # (\"a\", \"c\", \"f\")\n    \n    await store.alist_namespaces(prefix=(\"a\", \"b\"), max_depth=3)\n    # Returns: [(\"a\", \"b\", \"c\"), (\"a\", \"b\", \"d\"), (\"a\", \"b\", \"f\")]\n    \n[/code]\n\n###  `` `from_conn_string(conn_string: str, *, pipeline: bool = False, pool_config: Optional[PoolConfig] = None, index: Optional[PostgresIndexConfig] = None) -> Iterator[PostgresStore]` `classmethod` \u00b6\n\nCreate a new PostgresStore instance from a connection string.\n\nParameters:\n\n  * **`conn_string`** (`str`) \u2013 \n\nThe Postgres connection info string.\n\n  * **`pipeline`** (`bool`, default: `False` ) \u2013 \n\nwhether to use Pipeline\n\n  * **`pool_config`** (`Optional[PoolArgs]`, default: `None` ) \u2013 \n\nConfiguration for the connection pool. If provided, will create a connection pool and use it instead of a single connection. This overrides the `pipeline` argument.\n\n  * **`index`** (`Optional[PostgresIndexConfig]`, default: `None` ) \u2013 \n\nThe index configuration for the store.\n\n\n\n\nReturns:\n\n  * **`PostgresStore`** ( `Iterator[PostgresStore]` ) \u2013 \n\nA new PostgresStore instance.\n\n\n\n\n###  `` `setup() -> None` \u00b6\n\nSet up the store database.\n\nThis method creates the necessary tables in the Postgres database if they don't already exist and runs database migrations. It MUST be called directly by the user the first time the store is used.\n\n## Comments\n",
    "metadata": {
        "url": "https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.Item",
        "title": "Storage",
        "description": "Build language agents as graphs",
        "keywords": "No keywords"
    }
}